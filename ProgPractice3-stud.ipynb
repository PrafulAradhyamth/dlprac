{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Practice III"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:21:18.342916Z",
     "start_time": "2021-03-19T07:21:17.997829Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:21:18.372191Z",
     "start_time": "2021-03-19T07:21:18.344404Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----- useful functions from P2 -----\n",
    "def create_toy_dataset(self, n_samples=100):\n",
    "    x = np.linspace(-1,1,n_samples)\n",
    "    y = 0.1*x + x**2 + x**3\n",
    "    return x,y\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.sum((y_pred-y_true)**2)/y_true.shape[0]\n",
    "    # TODO\n",
    "\n",
    "def derivative_mse(y_true, y_pred):\n",
    "    return -2*(np.sum((y_pred-y_true))/y_true.shape[0])\n",
    "    # TODO\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#def update_parameters(parameters, gradient, learning_rate):\n",
    "#    # TODO\n",
    "    \n",
    "def update_parameters(w1, b1, w2, b2, dLdw1, dLdb1, dLdw2, dLdb2, learning_rate):\n",
    "    w1 -=(learning_rate*dLdw1.T)\n",
    "    b1 -=(learning_rate*dLdb1)\n",
    "    w2 -=(learning_rate*dLdw2)\n",
    "    b2 -=(learning_rate*dLdb2)\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "# ----- ReLU and its derivative -----\n",
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "    # TODO\n",
    "\n",
    "def derivative_relu(x):\n",
    "    return 1 * (x > 0)\n",
    "\n",
    "def forward_pass(x, w1, b1, w2, b2):\n",
    "    x=x.reshape(x.shape[0],1)\n",
    "    # Output layer\n",
    "    y_hat = np.dot(relu(np.dot(x, w1.T) + b1.T),w2) + b2\n",
    "    return y_hat\n",
    "\n",
    "def cal_gradient(x, y, y_hat, w1, b1, w2, b2):\n",
    "    # Hidden layer\n",
    "    Z1 = np.dot(x, w1.T) + b1.T\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    # Output layer\n",
    "    y_hat = np.dot(A1, w2) + b2\n",
    "    \n",
    "    \n",
    "    \n",
    "    m = x.shape[0]\n",
    "\n",
    "    # Output layer\n",
    "    dZ2 = y_hat - y\n",
    "    dLdw2 = (1 / m) * np.dot(A1.T, dZ2)\n",
    "    dLdb2 = (1 / m) * np.sum(dZ2, axis=0)\n",
    "\n",
    "    # Hidden layer\n",
    "    dZ1 = np.dot(dZ2, w2.T) * derivative_relu(A1)\n",
    "    dLdw1 = (1 / m) * np.dot(x.T, dZ1)\n",
    "    dLdb1 = (1 / m) * np.sum(dZ1, axis=0)\n",
    "    dLdb1 = dLdb1.reshape(dLdb1.shape[0],1)\n",
    "    \n",
    "    return dLdw1, dLdb1, dLdw2, dLdb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:21:18.382100Z",
     "start_time": "2021-03-19T07:21:18.374661Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, parameters, learning_rate, step):\n",
    "        np.random.seed(42)\n",
    "        n_nuerons_hidden_size = 500\n",
    "\n",
    "        self.w1 = np.random.randn(n_nuerons_hidden_size,1)\n",
    "        self.b1 = np.zeros((n_nuerons_hidden_size,1))\n",
    "        self.w2 = np.random.randn(n_nuerons_hidden_size, 1)\n",
    "        self.b2 = np.zeros((1, 1))\n",
    "        \n",
    "        self.learning_rate = 0.01\n",
    "        # TODO\n",
    "    \n",
    "    def train(self, x, y, epcohs):\n",
    "        n_inputs = x.shape[1]\n",
    "\n",
    "        a = np.array([1])\n",
    "        for i in range(epcohs):\n",
    "            # Forward propagation\n",
    "            #A1, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
    "\n",
    "            # Backward propagation\n",
    "            y_hat = forward_pass(x, self.w1, self.b1, self.w2, self.b2)\n",
    "            dLdw1, dLdb1, dLdw2, dLdb2 = cal_gradient(x, y, y_hat,self.w1, self.b1, self.w2, self.b2)\n",
    "            update_parameters(self.w1, self.b1, self.w2, self.b2, dLdw1, dLdb1, dLdw2, dLdb2, self.learning_rate)\n",
    "            \n",
    "\n",
    "            if (i+1) % 500 == 0:\n",
    "                loss = np.mean((y - y_hat) ** 2)\n",
    "                a = np.append(a, loss)\n",
    "                print(f\"Epoch: {i+1}, Loss: {loss}\")\n",
    "\n",
    "        return self.w1, self.b1, self.w2, self.b2\n",
    "    \n",
    "        \n",
    "    def predict(self, x):\n",
    "        x=x.reshape(x.shape[0],1)\n",
    "        # Output layer\n",
    "        y_hat = np.dot(sigmoid(np.dot(x, self.w1.T) + self.b1.T),self.w2) + self.b2\n",
    "        return y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:21:18.390037Z",
     "start_time": "2021-03-19T07:21:18.384084Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(method, num_neurons):\n",
    "\n",
    "    # TODO: hyperparameters, parameter initialization, Initialize weights and biases\n",
    "\n",
    "    np.random.seed(42)\n",
    "    num_neurons = n_nuerons_hidden_size\n",
    "    n_nuerons_hidden_size = 500\n",
    "\n",
    "    w1 = np.random.randn(n_nuerons_hidden_size,1)\n",
    "    b1 = np.zeros((n_nuerons_hidden_size,1))\n",
    "    w2 = np.random.randn(n_nuerons_hidden_size, 1)\n",
    "    b2 = np.zeros((1, 1))\n",
    "    # TODO\n",
    "    # return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train neural networks with different intialization methods\n",
    "# TODO: visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:13.812325Z",
     "start_time": "2021-03-19T07:22:13.630270Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: train neural networks with different learning rates\n",
    "# TODO: visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Network Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:39.751160Z",
     "start_time": "2021-03-19T07:22:39.571085Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: train neural networks with different capacities\n",
    "# TODO: visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:39.760578Z",
     "start_time": "2021-03-19T07:22:39.752620Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, parameters, learning_rate, step):\n",
    "        # TODO\n",
    "    \n",
    "    def train(self, x, y, epochs, decay):\n",
    "        # TODO\n",
    "        # You can modify here to add the gradients for the regularization terms\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train neural networks with different decays\n",
    "# TODO: visualize the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "830.4px",
    "left": "21px",
    "top": "133.6px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
